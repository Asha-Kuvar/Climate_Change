{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1975b2d3-dd46-40a8-9fa6-51a2d1b78531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (8.0.33)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: protobuf<=3.20.3,>=3.11.0 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from mysql-connector-python) (3.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas mysql-connector-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ab45ac1-fb40-42c4-9408-c2ca15a65571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\sairam\\desktop\\asha_mitraz\\flask\\climate_visualizer\\venv\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3357060-ce18-4559-9123-ba5eaf607e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "         Country  Year  Avg_Temperature_C  CO2_Emissions_MMT  \\\n",
      "0  United States  2000              17.61            2671.31   \n",
      "1  United States  2001              17.28            3098.08   \n",
      "2  United States  2002              17.30            1895.17   \n",
      "3  United States  2005              29.63            1078.40   \n",
      "4  United States  2008              24.81             327.61   \n",
      "\n",
      "   Deforestation_Rate_Percent  \n",
      "0                        2.22  \n",
      "1                        0.78  \n",
      "2                        2.33  \n",
      "3                        2.62  \n",
      "4                        3.08  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"C:/Users/Sairam/Downloads/climate_data (1).csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Dataset Preview:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d6871e0-dd86-4850-8df7-9eaeb68e7715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Data Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   country             303 non-null    object \n",
      " 1   year                303 non-null    int64  \n",
      " 2   avg_temperature     303 non-null    float64\n",
      " 3   co2_emissions       303 non-null    float64\n",
      " 4   deforestation_rate  303 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 12.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "df.dropna(inplace=True)  # Remove missing values\n",
    "df[\"year\"] = df[\"year\"].astype(int)  # Convert year to integer\n",
    "df[\"avg_temperature\"] = df[\"avg_temperature\"].astype(float)  # Convert temperature to float\n",
    "df[\"co2_emissions\"] = df[\"co2_emissions\"].astype(float)  # Convert CO2 emissions to float\n",
    "df[\"deforestation_rate\"] = df[\"deforestation_rate\"].astype(float)  # Convert deforestation rate to float\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nCleaned Data Summary:\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46b67f17-e05c-424a-8eb4-8de176c50650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    \"Avg_Temperature_C\": \"avg_temperature\",\n",
    "    \"CO2_Emissions_MMT\": \"co2_emissions\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Deforestation_Rate_Percent\": \"deforestation_rate\",\n",
    "    \"Year\": \"year\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea3a33ca-bf2b-4356-aed2-ee4051b9810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL successfully.\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "# Database Connection Configuration\n",
    "db_config = {\n",
    "    \"host\": \"localhost\",      # Change if MySQL runs on another server\n",
    "    \"user\": \"root\",  # Replace with MySQL username\n",
    "    \"password\": \"9949237758\",  # Replace with MySQL password\n",
    "    \"database\": \"climate_db\"  # Ensure this database exists\n",
    "}\n",
    "\n",
    "# Establish Connection\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"Connected to MySQL successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d92e47-12d7-408a-a045-bf30a0418209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 303 rows into MySQL.\n"
     ]
    }
   ],
   "source": [
    "# Insert Data into MySQL\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO climate_data (country, year, avg_temperature, co2_emissions, deforestation_rate)\n",
    "VALUES (%s, %s, %s, %s, %s)\n",
    "ON DUPLICATE KEY UPDATE \n",
    "    avg_temperature = VALUES(avg_temperature),\n",
    "    co2_emissions = VALUES(co2_emissions),\n",
    "    deforestation_rate = VALUES(deforestation_rate);\n",
    "\"\"\"\n",
    "\n",
    "data_tuples = [tuple(row) for row in df.itertuples(index=False, name=None)]\n",
    "\n",
    "# Insert data in batches\n",
    "cursor.executemany(insert_query, data_tuples)\n",
    "conn.commit()\n",
    "\n",
    "print(f\"Inserted {cursor.rowcount} rows into MySQL.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77bde489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1391bf53-2e8c-4e24-a73f-c09cfb38494e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Data (Assuming CSV file format)\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")  # Replace with your file path\n",
    "\n",
    "# Rename columns\n",
    "data.rename(columns={\n",
    "    \"Avg_Temperature_C\": \"avg_temperature\",\n",
    "    \"CO2_Emissions_MMT\": \"co2_emissions\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Deforestation_Rate_Percent\": \"deforestation_rate\",\n",
    "    \"Year\": \"year\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Encode Categorical Variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"country\"])\n",
    "\n",
    "# Selecting Features and Target Variables\n",
    "X = data[[\"Country_Encoded\", \"year\"]]\n",
    "y_temp = data[\"avg_temperature\"]\n",
    "y_co2 = data[\"co2_emissions\"]\n",
    "y_deforestation = data[\"deforestation_rate\"]\n",
    "\n",
    "# Split Data\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Save Models\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"Models trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e61dbbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Predicted Climate Impact:\n",
      "{'Predicted Temperature (°C)': np.float64(24.35), 'Predicted CO2 Emissions (MMT)': np.float64(1328.76), 'Predicted Deforestation Rate (%)': np.float64(2.51)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prediction Function\n",
    "def predict_climate(country, year):\n",
    "    # Load models and encoder\n",
    "    temp_model = joblib.load(\"temperature_model.pkl\")\n",
    "    co2_model = joblib.load(\"co2_model.pkl\")\n",
    "    deforestation_model = joblib.load(\"deforestation_model.pkl\")\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "    # Convert Country to Encoded Value\n",
    "    country_encoded = label_encoder.transform([country])[0]\n",
    "\n",
    "    # Prepare Input\n",
    "    input_data = np.array([[country_encoded, year]])\n",
    "\n",
    "    # Make Predictions\n",
    "    predicted_temp = temp_model.predict(input_data)[0]\n",
    "    predicted_co2 = co2_model.predict(input_data)[0]\n",
    "    predicted_deforestation = deforestation_model.predict(input_data)[0]\n",
    "\n",
    "    # Display Results\n",
    "    return {\n",
    "        \"Predicted Temperature (°C)\": round(predicted_temp, 2),\n",
    "        \"Predicted CO2 Emissions (MMT)\": round(predicted_co2, 2),\n",
    "        \"Predicted Deforestation Rate (%)\": round(predicted_deforestation, 2),\n",
    "    }\n",
    "\n",
    "# Example Usage\n",
    "country_name = input(\"🌍 Enter Country: \")\n",
    "year_input = int(input(\"📅 Enter Year: \"))\n",
    "\n",
    "prediction = predict_climate(country_name, year_input)\n",
    "print(\"📊 Predicted Climate Impact:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce930651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models trained and saved successfully!\n",
      "--- Model Performance for Temperature ---\n",
      "Mean Absolute Error (MAE): 7.19\n",
      "Mean Squared Error (MSE): 75.10\n",
      "Root Mean Squared Error (RMSE): 8.67\n",
      "R² Score: -0.38\n",
      "----------------------------------------\n",
      "--- Model Performance for CO2 Emissions ---\n",
      "Mean Absolute Error (MAE): 1165.44\n",
      "Mean Squared Error (MSE): 1991355.69\n",
      "Root Mean Squared Error (RMSE): 1411.15\n",
      "R² Score: -0.13\n",
      "----------------------------------------\n",
      "--- Model Performance for Deforestation Rate ---\n",
      "Mean Absolute Error (MAE): 1.43\n",
      "Mean Squared Error (MSE): 2.76\n",
      "Root Mean Squared Error (RMSE): 1.66\n",
      "R² Score: -0.21\n",
      "----------------------------------------\n",
      "Feature Importance (Country_Encoded, Year):\n",
      "Temperature Model: [0.4592159 0.5407841]\n",
      "CO2 Model: [0.49035023 0.50964977]\n",
      "Deforestation Model: [0.45590308 0.54409692]\n",
      "\n",
      "Sample Predictions for United States:\n",
      "Year 2025: Temp=18.06°C, CO2=2203.68 ppm, Deforestation=2.23%\n",
      "Year 2050: Temp=18.06°C, CO2=2203.68 ppm, Deforestation=2.23%\n",
      "Year 2075: Temp=18.06°C, CO2=2203.68 ppm, Deforestation=2.23%\n",
      "Year 2100: Temp=18.06°C, CO2=2203.68 ppm, Deforestation=2.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")  # Update path if needed\n",
    "\n",
    "# Encode categorical variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"Country\"])\n",
    "\n",
    "# Selecting features and target variables\n",
    "X = data[[\"Country_Encoded\", \"Year\"]]\n",
    "y_temp = data[\"Avg_Temperature_C\"]\n",
    "y_co2 = data[\"CO2_Emissions_MMT\"]\n",
    "y_deforestation = data[\"Deforestation_Rate_Percent\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X_scaled, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X_scaled, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X_scaled, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Save models and scaler\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"--- Model Performance for {target_name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(temp_model, X_test, y_temp_test, \"Temperature\")\n",
    "evaluate_model(co2_model, X_test, y_co2_test, \"CO2 Emissions\")\n",
    "evaluate_model(deforestation_model, X_test, y_deforestation_test, \"Deforestation Rate\")\n",
    "\n",
    "# Check feature importance\n",
    "print(\"Feature Importance (Country_Encoded, Year):\")\n",
    "print(\"Temperature Model:\", temp_model.feature_importances_)\n",
    "print(\"CO2 Model:\", co2_model.feature_importances_)\n",
    "print(\"Deforestation Model:\", deforestation_model.feature_importances_)\n",
    "\n",
    "# Test predictions for a sample country and different years\n",
    "sample_country = data[\"Country\"].iloc[0]\n",
    "country_encoded = label_encoder.transform([sample_country])[0]\n",
    "test_years = [2025, 2050, 2075, 2100]\n",
    "print(f\"\\nSample Predictions for {sample_country}:\")\n",
    "for year in test_years:\n",
    "    input_data = scaler.transform(np.array([[country_encoded, year]]))\n",
    "    temp_pred = temp_model.predict(input_data)[0]\n",
    "    co2_pred = co2_model.predict(input_data)[0]\n",
    "    def_pred = deforestation_model.predict(input_data)[0]\n",
    "    print(f\"Year {year}: Temp={temp_pred:.2f}°C, CO2={co2_pred:.2f} ppm, Deforestation={def_pred:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b48e3417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models trained and saved successfully!\n",
      "--- Model Performance for Temperature ---\n",
      "Mean Absolute Error (MAE): 7.19\n",
      "Mean Squared Error (MSE): 75.10\n",
      "Root Mean Squared Error (RMSE): 8.67\n",
      "R² Score: -0.38\n",
      "----------------------------------------\n",
      "--- Model Performance for CO2 Emissions ---\n",
      "Mean Absolute Error (MAE): 1165.44\n",
      "Mean Squared Error (MSE): 1991355.69\n",
      "Root Mean Squared Error (RMSE): 1411.15\n",
      "R² Score: -0.13\n",
      "----------------------------------------\n",
      "--- Model Performance for Deforestation Rate ---\n",
      "Mean Absolute Error (MAE): 1.43\n",
      "Mean Squared Error (MSE): 2.76\n",
      "Root Mean Squared Error (RMSE): 1.66\n",
      "R² Score: -0.21\n",
      "----------------------------------------\n",
      "Feature Importance (Country_Encoded, Year):\n",
      "Temperature Model: [0.4592159 0.5407841]\n",
      "CO2 Model: [0.49035023 0.50964977]\n",
      "Deforestation Model: [0.45590308 0.54409692]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")  # Update path if using augmented data\n",
    "\n",
    "# Encode Categorical Variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"Country\"])\n",
    "\n",
    "# Selecting Features and Target Variables\n",
    "X = data[[\"Country_Encoded\", \"Year\"]]\n",
    "y_temp = data[\"Avg_Temperature_C\"]\n",
    "y_co2 = data[\"CO2_Emissions_MMT\"]\n",
    "y_deforestation = data[\"Deforestation_Rate_Percent\"]\n",
    "\n",
    "# Scale Features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X_scaled, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X_scaled, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X_scaled, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Save Models and Scaler\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")\n",
    "\n",
    "# Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"--- Model Performance for {target_name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "evaluate_model(temp_model, X_test, y_temp_test, \"Temperature\")\n",
    "evaluate_model(co2_model, X_test, y_co2_test, \"CO2 Emissions\")\n",
    "evaluate_model(deforestation_model, X_test, y_deforestation_test, \"Deforestation Rate\")\n",
    "\n",
    "# Check Feature Importance\n",
    "print(\"Feature Importance (Country_Encoded, Year):\")\n",
    "print(\"Temperature Model:\", temp_model.feature_importances_)\n",
    "print(\"CO2 Model:\", co2_model.feature_importances_)\n",
    "print(\"Deforestation Model:\", deforestation_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad3e07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the Dataset...\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 5 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Country                     303 non-null    object \n",
      " 1   Year                        303 non-null    int64  \n",
      " 2   Avg_Temperature_C           303 non-null    float64\n",
      " 3   CO2_Emissions_MMT           303 non-null    float64\n",
      " 4   Deforestation_Rate_Percent  303 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 12.0+ KB\n",
      "None\n",
      "\n",
      "Year Range: 2000 to 2024\n",
      "\n",
      "Unique Countries: 20\n",
      "\n",
      "Missing Values:\n",
      "Country                       0\n",
      "Year                          0\n",
      "Avg_Temperature_C             0\n",
      "CO2_Emissions_MMT             0\n",
      "Deforestation_Rate_Percent    0\n",
      "dtype: int64\n",
      "\n",
      "Average Temperature by Year:\n",
      "Year\n",
      "2000    19.48\n",
      "2001    20.14\n",
      "2002    22.26\n",
      "2003    25.35\n",
      "2004    23.41\n",
      "2005    20.50\n",
      "2006    22.72\n",
      "2007    23.92\n",
      "2008    23.15\n",
      "2009    24.37\n",
      "2010    22.20\n",
      "2011    22.56\n",
      "2012    26.05\n",
      "2013    20.46\n",
      "2014    20.78\n",
      "2015    23.03\n",
      "2016    19.31\n",
      "2017    20.31\n",
      "2018    24.70\n",
      "2019    22.66\n",
      "2020    23.00\n",
      "2021    24.40\n",
      "2022    22.13\n",
      "2023    23.06\n",
      "2024    23.14\n",
      "Name: Avg_Temperature_C, dtype: float64\n",
      "\n",
      "Average CO2 Emissions by Year:\n",
      "Year\n",
      "2000    2388.55\n",
      "2001    1949.31\n",
      "2002    2108.09\n",
      "2003    2678.61\n",
      "2004    3008.96\n",
      "2005    2308.27\n",
      "2006    1631.24\n",
      "2007    1731.68\n",
      "2008    2787.39\n",
      "2009    1897.78\n",
      "2010    3213.35\n",
      "2011    2541.73\n",
      "2012    2342.09\n",
      "2013    2796.81\n",
      "2014    2227.98\n",
      "2015    2379.11\n",
      "2016    2666.66\n",
      "2017    2890.13\n",
      "2018    2766.06\n",
      "2019    2347.31\n",
      "2020    2840.62\n",
      "2021    2816.84\n",
      "2022    2201.66\n",
      "2023    2371.46\n",
      "2024    1664.73\n",
      "Name: CO2_Emissions_MMT, dtype: float64\n",
      "\n",
      "Average Deforestation_Rate_Percent Rate by Year:\n",
      "Year\n",
      "2000    1.52\n",
      "2001    3.06\n",
      "2002    2.66\n",
      "2003    2.78\n",
      "2004    2.33\n",
      "2005    2.64\n",
      "2006    2.28\n",
      "2007    2.67\n",
      "2008    1.97\n",
      "2009    2.87\n",
      "2010    2.52\n",
      "2011    2.30\n",
      "2012    2.40\n",
      "2013    2.58\n",
      "2014    2.75\n",
      "2015    2.35\n",
      "2016    2.28\n",
      "2017    2.61\n",
      "2018    3.38\n",
      "2019    2.75\n",
      "2020    2.18\n",
      "2021    3.27\n",
      "2022    1.57\n",
      "2023    2.69\n",
      "2024    2.34\n",
      "Name: Deforestation_Rate_Percent, dtype: float64\n",
      "\n",
      "Augmenting the Dataset...\n",
      "Augmented dataset saved as 'augmented_climate_data.csv'\n",
      "\n",
      "Augmented Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2503 entries, 0 to 2502\n",
      "Data columns (total 5 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Country                     2503 non-null   object \n",
      " 1   Year                        2503 non-null   int64  \n",
      " 2   Avg_Temperature_C           2503 non-null   float64\n",
      " 3   CO2_Emissions_MMT           2503 non-null   float64\n",
      " 4   Deforestation_Rate_Percent  2503 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 97.9+ KB\n",
      "None\n",
      "\n",
      "Year Range: 1990 to 2100\n",
      "\n",
      "Average Temperature by Year (sample):\n",
      "Year\n",
      "1990    21.00\n",
      "1991    21.05\n",
      "1992    21.04\n",
      "1993    21.04\n",
      "1994    21.11\n",
      "1995    21.15\n",
      "1996    21.15\n",
      "1997    21.18\n",
      "1998    21.19\n",
      "1999    21.19\n",
      "Name: Avg_Temperature_C, dtype: float64\n",
      "\n",
      "Average CO2 Emissions by Year (sample):\n",
      "Year\n",
      "1990    1475.52\n",
      "1991    1477.78\n",
      "1992    1484.67\n",
      "1993    1488.90\n",
      "1994    1493.32\n",
      "1995    1498.63\n",
      "1996    1505.72\n",
      "1997    1508.87\n",
      "1998    1514.12\n",
      "1999    1519.46\n",
      "Name: CO2_Emissions_MMT, dtype: float64\n",
      "\n",
      "Average Deforestation_Rate_Percent Rate by Year (sample):\n",
      "Year\n",
      "1990    0.11\n",
      "1991    0.14\n",
      "1992    0.13\n",
      "1993    0.16\n",
      "1994    0.17\n",
      "1995    0.20\n",
      "1996    0.25\n",
      "1997    0.26\n",
      "1998    0.33\n",
      "1999    0.35\n",
      "Name: Deforestation_Rate_Percent, dtype: float64\n",
      "\n",
      "Evaluating Models...\n",
      "--- Model Performance for Temperature ---\n",
      "Mean Absolute Error (MAE): 1.53\n",
      "Mean Squared Error (MSE): 13.41\n",
      "Root Mean Squared Error (RMSE): 3.66\n",
      "R² Score: 0.72\n",
      "----------------------------------------\n",
      "--- Model Performance for CO2 Emissions ---\n",
      "Mean Absolute Error (MAE): 320.93\n",
      "Mean Squared Error (MSE): 614974.47\n",
      "Root Mean Squared Error (RMSE): 784.20\n",
      "R² Score: 0.50\n",
      "----------------------------------------\n",
      "--- Model Performance for Deforestation_Rate_Percent Rate ---\n",
      "Mean Absolute Error (MAE): 0.46\n",
      "Mean Squared Error (MSE): 0.81\n",
      "Root Mean Squared Error (RMSE): 0.90\n",
      "R² Score: 0.92\n",
      "----------------------------------------\n",
      "Feature Importance (Country_Encoded, Year):\n",
      "Temperature Model: [0.84388939 0.15611061]\n",
      "CO2 Model: [0.73825306 0.26174694]\n",
      "Deforestation_Rate_Percent Model: [0.09748131 0.90251869]\n",
      "\n",
      "Sample Predictions for United States:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year 2025: Temp=17.80°C, CO2=2653.57 MMT, Deforestation_Rate_Percent=2.85%\n",
      "Year 2050: Temp=18.33°C, CO2=2778.68 MMT, Deforestation_Rate_Percent=5.40%\n",
      "Year 2075: Temp=18.85°C, CO2=2899.70 MMT, Deforestation_Rate_Percent=7.79%\n",
      "Year 2100: Temp=19.17°C, CO2=3030.13 MMT, Deforestation_Rate_Percent=10.24%\n",
      "✅ Models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Inspect the Dataset\n",
    "print(\"Inspecting the Dataset...\")\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nYear Range:\", data[\"Year\"].min(), \"to\", data[\"Year\"].max())\n",
    "print(\"\\nUnique Countries:\", data[\"Country\"].nunique())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Check trends by year\n",
    "print(\"\\nAverage Temperature by Year:\")\n",
    "print(data.groupby(\"Year\")[\"Avg_Temperature_C\"].mean().round(2))\n",
    "print(\"\\nAverage CO2 Emissions by Year:\")\n",
    "print(data.groupby(\"Year\")[\"CO2_Emissions_MMT\"].mean().round(2))\n",
    "print(\"\\nAverage Deforestation_Rate_Percent Rate by Year:\")\n",
    "print(data.groupby(\"Year\")[\"Deforestation_Rate_Percent\"].mean().round(2))\n",
    "\n",
    "# Step 2: Augment the Dataset\n",
    "print(\"\\nAugmenting the Dataset...\")\n",
    "countries = data[\"Country\"].unique()\n",
    "augmented_data = []\n",
    "temp_increase_per_year = 0.02  # °C per year\n",
    "co2_increase_per_year = 5      # MMT per year\n",
    "def_increase_per_year = 0.1    # % per year\n",
    "\n",
    "for country in countries:\n",
    "    country_data = data[data[\"Country\"] == country]\n",
    "    if country_data.empty:\n",
    "        continue\n",
    "    base_year = country_data[\"Year\"].max()\n",
    "    base_data = country_data[country_data[\"Year\"] == base_year].iloc[0]\n",
    "\n",
    "    # Past years (1990 to base_year-1)\n",
    "    for year in range(1990, base_year):\n",
    "        years_diff = base_year - year\n",
    "        augmented_data.append({\n",
    "            \"Country\": country,\n",
    "            \"Year\": year,\n",
    "            \"Avg_Temperature_C\": base_data[\"Avg_Temperature_C\"] - temp_increase_per_year * years_diff,\n",
    "            \"CO2_Emissions_MMT\": max(0, base_data[\"CO2_Emissions_MMT\"] - co2_increase_per_year * years_diff),\n",
    "            \"Deforestation_Rate_Percent\": max(0, base_data[\"Deforestation_Rate_Percent\"] - def_increase_per_year * years_diff)\n",
    "        })\n",
    "\n",
    "    # Future years (base_year+1 to 2100)\n",
    "    for year in range(base_year + 1, 2101):\n",
    "        years_diff = year - base_year\n",
    "        augmented_data.append({\n",
    "            \"Country\": country,\n",
    "            \"Year\": year,\n",
    "            \"Avg_Temperature_C\": base_data[\"Avg_Temperature_C\"] + temp_increase_per_year * years_diff,\n",
    "            \"CO2_Emissions_MMT\": base_data[\"CO2_Emissions_MMT\"] + co2_increase_per_year * years_diff,\n",
    "            \"Deforestation_Rate_Percent\": base_data[\"Deforestation_Rate_Percent\"] + def_increase_per_year * years_diff\n",
    "        })\n",
    "\n",
    "# Combine and save\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "data = pd.concat([data, augmented_df], ignore_index=True)\n",
    "data = data.dropna()\n",
    "\n",
    "# Add noise to avoid overfitting\n",
    "np.random.seed(42)\n",
    "data[\"Avg_Temperature_C\"] += np.random.normal(0, 0.1, len(data))\n",
    "data[\"CO2_Emissions_MMT\"] += np.random.normal(0, 5, len(data))\n",
    "data[\"Deforestation_Rate_Percent\"] += np.random.normal(0, 0.05, len(data))\n",
    "\n",
    "data.to_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\augmented_climate_data.csv\", index=False)\n",
    "print(\"Augmented dataset saved as 'augmented_climate_data.csv'\")\n",
    "\n",
    "# Reload augmented dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\augmented_climate_data.csv\")\n",
    "\n",
    "# Verify augmentation\n",
    "print(\"\\nAugmented Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nYear Range:\", data[\"Year\"].min(), \"to\", data[\"Year\"].max())\n",
    "print(\"\\nAverage Temperature by Year (sample):\")\n",
    "print(data.groupby(\"Year\")[\"Avg_Temperature_C\"].mean().round(2).head(10))\n",
    "print(\"\\nAverage CO2 Emissions by Year (sample):\")\n",
    "print(data.groupby(\"Year\")[\"CO2_Emissions_MMT\"].mean().round(2).head(10))\n",
    "print(\"\\nAverage Deforestation_Rate_Percent Rate by Year (sample):\")\n",
    "print(pd['deforestation_rate'].dtype())\n",
    "print(data.groupby(\"Year\")[\"Deforestation_Rate_Percent\"].mean().round(2).head(10))\n",
    "\n",
    "# Step 3: Preprocess Data\n",
    "# Encode categorical variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"Country\"])\n",
    "\n",
    "# Selecting features and target variables\n",
    "X = data[[\"Country_Encoded\", \"Year\"]]\n",
    "y_temp = data[\"Avg_Temperature_C\"]\n",
    "y_co2 = data[\"CO2_Emissions_MMT\"]\n",
    "y_deforestation = data[\"Deforestation_Rate_Percent\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X_scaled, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X_scaled, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X_scaled, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train Models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Step 5: Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"--- Model Performance for {target_name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nEvaluating Models...\")\n",
    "evaluate_model(temp_model, X_test, y_temp_test, \"Temperature\")\n",
    "evaluate_model(co2_model, X_test, y_co2_test, \"CO2 Emissions\")\n",
    "evaluate_model(deforestation_model, X_test, y_deforestation_test, \"Deforestation_Rate_Percent Rate\")\n",
    "\n",
    "# Check feature importance\n",
    "print(\"Feature Importance (Country_Encoded, Year):\")\n",
    "print(\"Temperature Model:\", temp_model.feature_importances_)\n",
    "print(\"CO2 Model:\", co2_model.feature_importances_)\n",
    "print(\"Deforestation_Rate_Percent Model:\", deforestation_model.feature_importances_)\n",
    "\n",
    "# Test predictions for United States\n",
    "sample_country = \"United States\"\n",
    "try:\n",
    "    country_encoded = label_encoder.transform([sample_country])[0]\n",
    "    test_years = [2025, 2050, 2075, 2100]\n",
    "    print(f\"\\nSample Predictions for {sample_country}:\")\n",
    "    for year in test_years:\n",
    "        input_data = scaler.transform(np.array([[country_encoded, year]]))\n",
    "        temp_pred = temp_model.predict(input_data)[0]\n",
    "        co2_pred = co2_model.predict(input_data)[0]\n",
    "        def_pred = deforestation_model.predict(input_data)[0]\n",
    "        print(f\"Year {year}: Temp={temp_pred:.2f}°C, CO2={co2_pred:.2f} MMT, Deforestation_Rate_Percent={def_pred:.2f}%\")\n",
    "except ValueError:\n",
    "    print(f\"Country '{sample_country}' not found in dataset\")\n",
    "\n",
    "# Step 6: Save Models and Scalers\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b54101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models and scalers loaded successfully!\n",
      "\n",
      "Available Countries:\n",
      "Argentina, Australia, Brazil, Canada, China, France, Germany, India, Indonesia, Italy, Japan, Mexico, Russia, Saudi Arabia, South Africa, South Korea, Spain, Turkey, United Kingdom, United States\n",
      "\n",
      "Predictions for Brazil in 2090:\n",
      "Temperature: 20.97°C\n",
      "CO2 Emissions: 4608.01 MMT\n",
      "Deforestation Rate: 8.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Step 1: Load the trained models and scalers\n",
    "try:\n",
    "    temp_model = joblib.load(\"temperature_model.pkl\")\n",
    "    co2_model = joblib.load(\"co2_model.pkl\")\n",
    "    deforestation_model = joblib.load(\"deforestation_model.pkl\")\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "    scaler = joblib.load(\"scaler.pkl\")\n",
    "    print(\"✅ Models and scalers loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Step 2: Display available countries\n",
    "available_countries = label_encoder.classes_.tolist()\n",
    "print(\"\\nAvailable Countries:\")\n",
    "print(\", \".join(available_countries))\n",
    "\n",
    "# Step 3: Take user input once\n",
    "# Input country\n",
    "country = input(\"\\nEnter a country: \").strip()\n",
    "\n",
    "# Validate country\n",
    "if country not in available_countries:\n",
    "    print(f\"Error: Country '{country}' not found. Please choose from the available countries.\")\n",
    "    exit()\n",
    "\n",
    "# Input year\n",
    "try:\n",
    "    year = int(input(\"Enter a year (1990–2100): \").strip())\n",
    "    if year < 1990 or year > 2100:\n",
    "        print(\"Error: Year must be between 1990 and 2100.\")\n",
    "        exit()\n",
    "except ValueError:\n",
    "    print(\"Error: Year must be a valid integer.\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Encode the country and prepare input\n",
    "country_encoded = label_encoder.transform([country])[0]\n",
    "input_data = np.array([[country_encoded, year]])\n",
    "input_data_scaled = scaler.transform(input_data)\n",
    "\n",
    "# Step 5: Make predictions\n",
    "predicted_temp = temp_model.predict(input_data_scaled)[0]\n",
    "predicted_co2 = co2_model.predict(input_data_scaled)[0]\n",
    "predicted_def = deforestation_model.predict(input_data_scaled)[0]\n",
    "\n",
    "# Step 6: Display predictions\n",
    "print(f\"\\nPredictions for {country} in {year}:\")\n",
    "print(f\"Temperature: {predicted_temp:.2f}°C\")\n",
    "print(f\"CO2 Emissions: {predicted_co2:.2f} MMT\")\n",
    "print(f\"Deforestation Rate: {predicted_def:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01baf492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the Dataset...\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   country             303 non-null    object \n",
      " 1   year                303 non-null    int64  \n",
      " 2   avg_temperature     303 non-null    float64\n",
      " 3   co2_emissions       303 non-null    float64\n",
      " 4   deforestation_rate  303 non-null    float64\n",
      "dtypes: float64(3), int64(1), object(1)\n",
      "memory usage: 12.0+ KB\n",
      "None\n",
      "\n",
      "Year Range: 2000 to 2024\n",
      "\n",
      "Unique Countries: 20\n",
      "\n",
      "Missing Values:\n",
      "country               0\n",
      "year                  0\n",
      "avg_temperature       0\n",
      "co2_emissions         0\n",
      "deforestation_rate    0\n",
      "dtype: int64\n",
      "\n",
      "Average Temperature by Year:\n",
      "year\n",
      "2000    19.48\n",
      "2001    20.14\n",
      "2002    22.26\n",
      "2003    25.35\n",
      "2004    23.41\n",
      "2005    20.50\n",
      "2006    22.72\n",
      "2007    23.92\n",
      "2008    23.15\n",
      "2009    24.37\n",
      "2010    22.20\n",
      "2011    22.56\n",
      "2012    26.05\n",
      "2013    20.46\n",
      "2014    20.78\n",
      "2015    23.03\n",
      "2016    19.31\n",
      "2017    20.31\n",
      "2018    24.70\n",
      "2019    22.66\n",
      "2020    23.00\n",
      "2021    24.40\n",
      "2022    22.13\n",
      "2023    23.06\n",
      "2024    23.14\n",
      "Name: avg_temperature, dtype: float64\n",
      "\n",
      "Average CO2 Emissions by Year:\n",
      "year\n",
      "2000    2388.55\n",
      "2001    1949.31\n",
      "2002    2108.09\n",
      "2003    2678.61\n",
      "2004    3008.96\n",
      "2005    2308.27\n",
      "2006    1631.24\n",
      "2007    1731.68\n",
      "2008    2787.39\n",
      "2009    1897.78\n",
      "2010    3213.35\n",
      "2011    2541.73\n",
      "2012    2342.09\n",
      "2013    2796.81\n",
      "2014    2227.98\n",
      "2015    2379.11\n",
      "2016    2666.66\n",
      "2017    2890.13\n",
      "2018    2766.06\n",
      "2019    2347.31\n",
      "2020    2840.62\n",
      "2021    2816.84\n",
      "2022    2201.66\n",
      "2023    2371.46\n",
      "2024    1664.73\n",
      "Name: co2_emissions, dtype: float64\n",
      "\n",
      "Average Deforestation Rate by Year:\n",
      "year\n",
      "2000    1.52\n",
      "2001    3.06\n",
      "2002    2.66\n",
      "2003    2.78\n",
      "2004    2.33\n",
      "2005    2.64\n",
      "2006    2.28\n",
      "2007    2.67\n",
      "2008    1.97\n",
      "2009    2.87\n",
      "2010    2.52\n",
      "2011    2.30\n",
      "2012    2.40\n",
      "2013    2.58\n",
      "2014    2.75\n",
      "2015    2.35\n",
      "2016    2.28\n",
      "2017    2.61\n",
      "2018    3.38\n",
      "2019    2.75\n",
      "2020    2.18\n",
      "2021    3.27\n",
      "2022    1.57\n",
      "2023    2.69\n",
      "2024    2.34\n",
      "Name: deforestation_rate, dtype: float64\n",
      "\n",
      "Evaluating Models...\n",
      "--- Model Performance for Temperature ---\n",
      "Mean Absolute Error (MAE): 7.19\n",
      "Mean Squared Error (MSE): 75.10\n",
      "Root Mean Squared Error (RMSE): 8.67\n",
      "R² Score: -0.38\n",
      "----------------------------------------\n",
      "--- Model Performance for CO2 Emissions ---\n",
      "Mean Absolute Error (MAE): 1165.44\n",
      "Mean Squared Error (MSE): 1991355.69\n",
      "Root Mean Squared Error (RMSE): 1411.15\n",
      "R² Score: -0.13\n",
      "----------------------------------------\n",
      "--- Model Performance for Deforestation Rate ---\n",
      "Mean Absolute Error (MAE): 1.43\n",
      "Mean Squared Error (MSE): 2.76\n",
      "Root Mean Squared Error (RMSE): 1.66\n",
      "R² Score: -0.21\n",
      "----------------------------------------\n",
      "Feature Importance (country_encoded, year):\n",
      "Temperature Model: [0.4592159 0.5407841]\n",
      "CO2 Model: [0.49035023 0.50964977]\n",
      "Deforestation Model: [0.45590308 0.54409692]\n",
      "\n",
      "Sample Predictions for United States:\n",
      "Year 2025: Temp=18.06°C, CO2=2203.68 MMT, Deforestation=2.23%\n",
      "Year 2050: Temp=18.06°C, CO2=2203.68 MMT, Deforestation=2.23%\n",
      "Year 2075: Temp=18.06°C, CO2=2203.68 MMT, Deforestation=2.23%\n",
      "Year 2100: Temp=18.06°C, CO2=2203.68 MMT, Deforestation=2.23%\n",
      "✅ Models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Inspect the Dataset\n",
    "print(\"Inspecting the Dataset...\")\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")\n",
    "\n",
    "# Rename columns\n",
    "data.rename(columns={\n",
    "    \"Avg_Temperature_C\": \"avg_temperature\",\n",
    "    \"CO2_Emissions_MMT\": \"co2_emissions\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Deforestation_Rate_Percent\": \"deforestation_rate\",\n",
    "    \"Year\": \"year\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nYear Range:\", data[\"year\"].min(), \"to\", data[\"year\"].max())\n",
    "print(\"\\nUnique Countries:\", data[\"country\"].nunique())\n",
    "print(\"\\nMissing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Check trends by year\n",
    "print(\"\\nAverage Temperature by Year:\")\n",
    "print(data.groupby(\"year\")[\"avg_temperature\"].mean().round(2))\n",
    "print(\"\\nAverage CO2 Emissions by Year:\")\n",
    "print(data.groupby(\"year\")[\"co2_emissions\"].mean().round(2))\n",
    "print(\"\\nAverage Deforestation Rate by Year:\")\n",
    "print(data.groupby(\"year\")[\"deforestation_rate\"].mean().round(2))\n",
    "\n",
    "# Step 2: Preprocess Data\n",
    "# Normalize the country column to handle case sensitivity\n",
    "data[\"country\"] = data[\"country\"].str.strip().str.title()\n",
    "\n",
    "# Encode categorical variable (country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"country_encoded\"] = label_encoder.fit_transform(data[\"country\"])\n",
    "\n",
    "# Selecting features and target variables\n",
    "X = data[[\"country_encoded\", \"year\"]].values  # Convert to numpy array to avoid feature names warning\n",
    "y_temp = data[\"avg_temperature\"]\n",
    "y_co2 = data[\"co2_emissions\"]\n",
    "y_deforestation = data[\"deforestation_rate\"]\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data (80% train, 20% test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X_scaled, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X_scaled, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X_scaled, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train Models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Step 4: Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"--- Model Performance for {target_name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nEvaluating Models...\")\n",
    "evaluate_model(temp_model, X_test, y_temp_test, \"Temperature\")\n",
    "evaluate_model(co2_model, X_test, y_co2_test, \"CO2 Emissions\")\n",
    "evaluate_model(deforestation_model, X_test, y_deforestation_test, \"Deforestation Rate\")\n",
    "\n",
    "# Check feature importance\n",
    "print(\"Feature Importance (country_encoded, year):\")\n",
    "print(\"Temperature Model:\", temp_model.feature_importances_)\n",
    "print(\"CO2 Model:\", co2_model.feature_importances_)\n",
    "print(\"Deforestation Model:\", deforestation_model.feature_importances_)\n",
    "\n",
    "# Step 5: Test Predictions for United States\n",
    "sample_country = \"United States\"\n",
    "try:\n",
    "    country_encoded = label_encoder.transform([sample_country])[0]\n",
    "    test_years = [2025, 2050, 2075, 2100]\n",
    "    print(f\"\\nSample Predictions for {sample_country}:\")\n",
    "    for year in test_years:\n",
    "        input_data = scaler.transform(np.array([[country_encoded, year]]))\n",
    "        temp_pred = temp_model.predict(input_data)[0]\n",
    "        co2_pred = co2_model.predict(input_data)[0]\n",
    "        def_pred = deforestation_model.predict(input_data)[0]\n",
    "        print(f\"Year {year}: Temp={temp_pred:.2f}°C, CO2={co2_pred:.2f} MMT, Deforestation={def_pred:.2f}%\")\n",
    "except ValueError:\n",
    "    print(f\"Country '{sample_country}' not found in dataset\")\n",
    "\n",
    "# Step 6: Save Models and Scaler\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8748b178",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense, Dropout\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5929\u001b[0m\n\u001b[0;32m   5923\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m   5924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_to_proto_function\u001b[39m(\n\u001b[0;32m   5928\u001b[0m     collection_name,\n\u001b[1;32m-> 5929\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   5930\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the to_proto function for collection_name.\"\"\"\u001b[39;00m\n\u001b[0;32m   5931\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:433\u001b[0m, in \u001b[0;36mOptional\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Optional type.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mOptional[X] is equivalent to Union[X, None].\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m arg \u001b[38;5;241m=\u001b[39m _type_check(parameters, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a single type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:421\u001b[0m, in \u001b[0;36mUnion\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    419\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[arg, ...]: each arg must be a type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_type_check(p, msg) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[1;32m--> 421\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[43m_remove_dups_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parameters) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parameters[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:215\u001b[0m, in \u001b[0;36m_remove_dups_flatten\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    213\u001b[0m         params\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Weed out strict duplicates, preserving the first of each occurrence.\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m all_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_params) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(params):\n\u001b[0;32m    217\u001b[0m     new_params \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load Data\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")  # Replace with your file path\n",
    "\n",
    "# Encode Categorical Variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"Country\"])\n",
    "\n",
    "# Select Features and Target Variables\n",
    "X = data[[\"Country_Encoded\", \"Year\"]].values  # Convert to NumPy array\n",
    "y_temp = data[\"Avg_Temperature_C\"].values\n",
    "y_co2 = data[\"CO2_Emissions_MMT\"].values\n",
    "y_deforestation = data[\"Deforestation_Rate_Percent\"].values\n",
    "\n",
    "# Normalize Data\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y_temp = MinMaxScaler()\n",
    "scaler_y_co2 = MinMaxScaler()\n",
    "scaler_y_deforestation = MinMaxScaler()\n",
    "\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "y_temp_scaled = scaler_y_temp.fit_transform(y_temp.reshape(-1, 1))\n",
    "y_co2_scaled = scaler_y_co2.fit_transform(y_co2.reshape(-1, 1))\n",
    "y_deforestation_scaled = scaler_y_deforestation.fit_transform(y_deforestation.reshape(-1, 1))\n",
    "\n",
    "# Reshape Data for LSTM (Samples, Time Steps, Features)\n",
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "# Split Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X_reshaped, y_temp_scaled, test_size=0.2, shuffle=False)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X_reshaped, y_co2_scaled, test_size=0.2, shuffle=False)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X_reshaped, y_deforestation_scaled, test_size=0.2, shuffle=False)\n",
    "\n",
    "# LSTM Model Function\n",
    "def build_lstm_model():\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, input_shape=(1, X_reshaped.shape[2])),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)  # Output layer\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train Models\n",
    "temp_model = build_lstm_model()\n",
    "co2_model = build_lstm_model()\n",
    "deforestation_model = build_lstm_model()\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train, epochs=50, batch_size=16, validation_data=(X_test, y_temp_test), verbose=1)\n",
    "co2_model.fit(X_train, y_co2_train, epochs=50, batch_size=16, validation_data=(X_test, y_co2_test), verbose=1)\n",
    "deforestation_model.fit(X_train, y_deforestation_train, epochs=50, batch_size=16, validation_data=(X_test, y_deforestation_test), verbose=1)\n",
    "\n",
    "# Save Models\n",
    "temp_model.save(\"temperature_lstm_model.h5\")\n",
    "co2_model.save(\"co2_lstm_model.h5\")\n",
    "deforestation_model.save(\"deforestation_lstm_model.h5\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "joblib.dump(scaler_x, \"scaler_x.pkl\")\n",
    "joblib.dump(scaler_y_temp, \"scaler_y_temp.pkl\")\n",
    "joblib.dump(scaler_y_co2, \"scaler_y_co2.pkl\")\n",
    "joblib.dump(scaler_y_deforestation, \"scaler_y_deforestation.pkl\")\n",
    "\n",
    "print(\"✅ LSTM Models trained and saved successfully!\")\n",
    "\n",
    "# Function to Predict Using LSTM Model\n",
    "def predict_climate_lstm(country, year):\n",
    "    # Load models and encoders\n",
    "    temp_model = tf.keras.models.load_model(\"temperature_lstm_model.h5\")\n",
    "    co2_model = tf.keras.models.load_model(\"co2_lstm_model.h5\")\n",
    "    deforestation_model = tf.keras.models.load_model(\"deforestation_lstm_model.h5\")\n",
    "    \n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "    scaler_x = joblib.load(\"scaler_x.pkl\")\n",
    "    scaler_y_temp = joblib.load(\"scaler_y_temp.pkl\")\n",
    "    scaler_y_co2 = joblib.load(\"scaler_y_co2.pkl\")\n",
    "    scaler_y_deforestation = joblib.load(\"scaler_y_deforestation.pkl\")\n",
    "\n",
    "    # Convert Country to Encoded Value\n",
    "    country_encoded = label_encoder.transform([country])[0]\n",
    "\n",
    "    # Prepare Input\n",
    "    input_data = np.array([[country_encoded, year]])\n",
    "    input_scaled = scaler_x.transform(input_data)\n",
    "    input_reshaped = input_scaled.reshape((1, 1, input_scaled.shape[1]))\n",
    "\n",
    "    # Make Predictions (Inverse Transform to Original Scale)\n",
    "    predicted_temp = scaler_y_temp.inverse_transform(temp_model.predict(input_reshaped))[0][0]\n",
    "    predicted_co2 = scaler_y_co2.inverse_transform(co2_model.predict(input_reshaped))[0][0]\n",
    "    predicted_deforestation = scaler_y_deforestation.inverse_transform(deforestation_model.predict(input_reshaped))[0][0]\n",
    "\n",
    "    return {\n",
    "        \"Predicted Temperature (°C)\": round(predicted_temp, 2),\n",
    "        \"Predicted CO2 Emissions (MMT)\": round(predicted_co2, 2),\n",
    "        \"Predicted Deforestation Rate (%)\": round(predicted_deforestation, 2),\n",
    "    }\n",
    "\n",
    "# Example Usage\n",
    "country_name = input(\"🌍 Enter Country: \")\n",
    "year_input = int(input(\"📅 Enter Year: \"))\n",
    "\n",
    "prediction = predict_climate_lstm(country_name, year_input)\n",
    "print(\"📊 Predicted Climate Impact:\")\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee715cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models trained and saved successfully!\n",
      "--- Model Performance for Temperature ---\n",
      "Mean Absolute Error (MAE): 6.88\n",
      "Mean Squared Error (MSE): 69.88\n",
      "Root Mean Squared Error (RMSE): 8.36\n",
      "R² Score: -0.29\n",
      "----------------------------------------\n",
      "--- Model Performance for CO2 Emissions ---\n",
      "Mean Absolute Error (MAE): 1131.76\n",
      "Mean Squared Error (MSE): 1923099.03\n",
      "Root Mean Squared Error (RMSE): 1386.76\n",
      "R² Score: -0.09\n",
      "----------------------------------------\n",
      "--- Model Performance for Deforestation Rate ---\n",
      "Mean Absolute Error (MAE): 1.41\n",
      "Mean Squared Error (MSE): 2.70\n",
      "Root Mean Squared Error (RMSE): 1.64\n",
      "R² Score: -0.19\n",
      "----------------------------------------\n",
      "📊 Predicted Climate Impact:\n",
      "{'Predicted Temperature (°C)': np.float64(24.35), 'Predicted CO2 Emissions (MMT)': np.float64(1328.76), 'Predicted Deforestation Rate (%)': np.float64(2.51)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "\n",
    "# Load Data (Replace 'climate_data.csv' with your actual file)\n",
    "data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")  # Replace with your file path\n",
    "\n",
    "# Encode Categorical Variable (Country)\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"Country\"])\n",
    "\n",
    "# Selecting Features and Target Variables\n",
    "X = data[[\"Country_Encoded\", \"Year\"]]\n",
    "y_temp = data[\"Avg_Temperature_C\"]\n",
    "y_co2 = data[\"CO2_Emissions_MMT\"]\n",
    "y_deforestation = data[\"Deforestation_Rate_Percent\"]\n",
    "\n",
    "# Split Data (80% Train, 20% Test)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X, y_temp, test_size=0.2, random_state=42)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X, y_co2, test_size=0.2, random_state=42)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X, y_deforestation, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Models\n",
    "temp_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "co2_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "deforestation_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "temp_model.fit(X_train, y_temp_train)\n",
    "co2_model.fit(X_train, y_co2_train)\n",
    "deforestation_model.fit(X_train, y_deforestation_train)\n",
    "\n",
    "# Save Models\n",
    "joblib.dump(temp_model, \"temperature_model.pkl\")\n",
    "joblib.dump(co2_model, \"co2_model.pkl\")\n",
    "joblib.dump(deforestation_model, \"deforestation_model.pkl\")\n",
    "joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "print(\"✅ Models trained and saved successfully!\")\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, X_test, y_test, target_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"--- Model Performance for {target_name} ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "    print(f\"R² Score: {r2:.2f}\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "# Evaluate models\n",
    "evaluate_model(temp_model, X_test, y_temp_test, \"Temperature\")\n",
    "evaluate_model(co2_model, X_test, y_co2_test, \"CO2 Emissions\")\n",
    "evaluate_model(deforestation_model, X_test, y_deforestation_test, \"Deforestation Rate\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict_climate(country, year):\n",
    "    # Load models and encoder\n",
    "    temp_model = joblib.load(\"temperature_model.pkl\")\n",
    "    co2_model = joblib.load(\"co2_model.pkl\")\n",
    "    deforestation_model = joblib.load(\"deforestation_model.pkl\")\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "    # Convert Country to Encoded Value\n",
    "    country_encoded = label_encoder.transform([country])[0]\n",
    "\n",
    "    # Prepare Input\n",
    "    input_data = np.array([[country_encoded, year]])\n",
    "\n",
    "    # Make Predictions\n",
    "    predicted_temp = temp_model.predict(input_data)[0]\n",
    "    predicted_co2 = co2_model.predict(input_data)[0]\n",
    "    predicted_deforestation = deforestation_model.predict(input_data)[0]\n",
    "\n",
    "    # Display Results\n",
    "    return {\n",
    "        \"Predicted Temperature (°C)\": round(predicted_temp, 2),\n",
    "        \"Predicted CO2 Emissions (MMT)\": round(predicted_co2, 2),\n",
    "        \"Predicted Deforestation Rate (%)\": round(predicted_deforestation, 2),\n",
    "    }\n",
    "\n",
    "# Example Usage\n",
    "country_name = input(\"🌍 Enter Country: \")\n",
    "year_input = int(input(\"📅 Enter Year: \"))\n",
    "\n",
    "prediction = predict_climate(country_name, year_input)\n",
    "print(\"📊 Predicted Climate Impact:\")\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de767ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\__init__.py:48\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     46\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\autograph\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\core\\ag_ctx.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[0;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\__init__.py:17\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\utils\\context_managers.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[1;32mc:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:5929\u001b[0m\n\u001b[0;32m   5923\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m   5924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_to_proto_function\u001b[39m(\n\u001b[0;32m   5928\u001b[0m     collection_name,\n\u001b[1;32m-> 5929\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   5930\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the to_proto function for collection_name.\"\"\"\u001b[39;00m\n\u001b[0;32m   5931\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:433\u001b[0m, in \u001b[0;36mOptional\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Optional type.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m \n\u001b[0;32m    430\u001b[0m \u001b[38;5;124;03mOptional[X] is equivalent to Union[X, None].\u001b[39;00m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    432\u001b[0m arg \u001b[38;5;241m=\u001b[39m _type_check(parameters, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a single type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:243\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:316\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[1;32m--> 316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:421\u001b[0m, in \u001b[0;36mUnion\u001b[1;34m(self, parameters)\u001b[0m\n\u001b[0;32m    419\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[arg, ...]: each arg must be a type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_type_check(p, msg) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[1;32m--> 421\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[43m_remove_dups_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parameters) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parameters[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\typing.py:215\u001b[0m, in \u001b[0;36m_remove_dups_flatten\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    213\u001b[0m         params\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;66;03m# Weed out strict duplicates, preserving the first of each occurrence.\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m all_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_params) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(params):\n\u001b[0;32m    217\u001b[0m     new_params \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import LSTM, Dense, Dropout\n",
    "    print(\"Using standalone keras imports\")\n",
    "except:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    print(\"Using tensorflow.keras imports\")\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Verify imports\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "try:\n",
    "    import keras\n",
    "    print(\"Keras Version:\", keras.__version__)\n",
    "except:\n",
    "    print(\"Standalone Keras not installed, using tensorflow.keras\")\n",
    "\n",
    "# Load Data\n",
    "try:\n",
    "    data = pd.read_csv(r\"C:\\Users\\Sairam\\Desktop\\Asha_MITRAz\\flask\\climate_visualizer\\climate_data (1).csv\")\n",
    "    data.rename(columns={\n",
    "        \"Avg_Temperature_C\": \"avg_temperature\",\n",
    "        \"CO2_Emissions_MMT\": \"co2_emissions\",\n",
    "        \"Country\": \"country\",\n",
    "        \"Deforestation_Rate_Percent\": \"deforestation_rate\",\n",
    "        \"Year\": \"year\"\n",
    "    }, inplace=True)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: CSV file not found. Please check the file path.\")\n",
    "    exit(1)\n",
    "\n",
    "# Sort data by country and year\n",
    "data = data.sort_values(by=[\"country\", \"year\"])\n",
    "\n",
    "# Encode Country\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"Country_Encoded\"] = label_encoder.fit_transform(data[\"country\"])\n",
    "\n",
    "# Normalize Features and Targets\n",
    "scaler_x = MinMaxScaler()\n",
    "data[[\"year\", \"Country_Encoded\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]] = scaler_x.fit_transform(\n",
    "    data[[\"year\", \"Country_Encoded\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]]\n",
    ")\n",
    "\n",
    "# Create Sequences for LSTM\n",
    "def create_sequences(data, seq_length=5):\n",
    "    X, y_temp, y_co2, y_deforestation = [], [], [], []\n",
    "    for country in data[\"country\"].unique():\n",
    "        country_data = data[data[\"country\"] == country].sort_values(\"year\")\n",
    "        if len(country_data) < seq_length + 1:\n",
    "            print(f\"Warning: Not enough data for {country} (only {len(country_data)} rows)\")\n",
    "            continue\n",
    "        for i in range(len(country_data) - seq_length):\n",
    "            seq = country_data[[\"Country_Encoded\", \"year\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]].iloc[i:i+seq_length].values\n",
    "            X.append(seq)\n",
    "            y_temp.append(country_data[\"avg_temperature\"].iloc[i+seq_length])\n",
    "            y_co2.append(country_data[\"co2_emissions\"].iloc[i+seq_length])\n",
    "            y_deforestation.append(country_data[\"deforestation_rate\"].iloc[i+seq_length])\n",
    "    return np.array(X), np.array(y_temp), np.array(y_co2), np.array(y_deforestation)\n",
    "\n",
    "seq_length = 5\n",
    "X, y_temp, y_co2, y_deforestation = create_sequences(data, seq_length)\n",
    "\n",
    "if X.size == 0:\n",
    "    print(\"Error: No sequences created. Check dataset size or sequence length.\")\n",
    "    exit(1)\n",
    "\n",
    "# Split Data (no shuffling to preserve temporal order)\n",
    "X_train, X_test, y_temp_train, y_temp_test = train_test_split(X, y_temp, test_size=0.2, shuffle=False)\n",
    "_, _, y_co2_train, y_co2_test = train_test_split(X, y_co2, test_size=0.2, shuffle=False)\n",
    "_, _, y_deforestation_train, y_deforestation_test = train_test_split(X, y_deforestation, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Build LSTM Model\n",
    "def build_lstm_model(seq_length, n_features):\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, n_features)),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model\n",
    "\n",
    "# Train Models\n",
    "try:\n",
    "    temp_model = build_lstm_model(seq_length, X.shape[2])\n",
    "    co2_model = build_lstm_model(seq_length, X.shape[2])\n",
    "    deforestation_model = build_lstm_model(seq_length, X.shape[2])\n",
    "\n",
    "    temp_model.fit(X_train, y_temp_train, epochs=50, batch_size=16, validation_data=(X_test, y_temp_test), verbose=1)\n",
    "    co2_model.fit(X_train, y_co2_train, epochs=50, batch_size=16, validation_data=(X_test, y_co2_test), verbose=1)\n",
    "    deforestation_model.fit(X_train, y_deforestation_train, epochs=50, batch_size=16, validation_data=(X_test, y_deforestation_test), verbose=1)\n",
    "except Exception as e:\n",
    "    print(\"Error during model training:\", str(e))\n",
    "    exit(1)\n",
    "\n",
    "# Save Models\n",
    "try:\n",
    "    temp_model.save(\"temperature_lstm_model.h5\")\n",
    "    co2_model.save(\"co2_lstm_model.h5\")\n",
    "    deforestation_model.save(\"deforestation_lstm_model.h5\")\n",
    "    joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "    joblib.dump(scaler_x, \"scaler_x.pkl\")\n",
    "    print(\"✅ LSTM Models trained and saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving models:\", str(e))\n",
    "    exit(1)\n",
    "\n",
    "# Prediction Function\n",
    "def predict_climate_lstm(country, year, data, seq_length=5):\n",
    "    try:\n",
    "        temp_model = tf.keras.models.load_model(\"temperature_lstm_model.h5\")\n",
    "        co2_model = tf.keras.models.load_model(\"co2_lstm_model.h5\")\n",
    "        deforestation_model = tf.keras.models.load_model(\"deforestation_lstm_model.h5\")\n",
    "        label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "        scaler_x = joblib.load(\"scaler_x.pkl\")\n",
    "    except Exception as e:\n",
    "        print(\"Error loading models:\", str(e))\n",
    "        return None\n",
    "    \n",
    "    # Ensure country is a string\n",
    "    if isinstance(country, list):\n",
    "        country = country[0]\n",
    "    elif not isinstance(country, str):\n",
    "        raise ValueError(f\"Country must be a string, got {type(country)}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    country_data = data[data[\"country\"] == country].sort_values(\"year\").copy()\n",
    "    if len(country_data) < seq_length:\n",
    "        raise ValueError(f\"Not enough data for {country} to create a sequence of length {seq_length}\")\n",
    "    \n",
    "    # Normalize year in the data\n",
    "    country_data[[\"year\", \"Country_Encoded\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]] = scaler_x.transform(\n",
    "        country_data[[\"year\", \"Country_Encoded\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]]\n",
    "    )\n",
    "    country_data[\"Country_Encoded\"] = label_encoder.transform([country])[0]\n",
    "    \n",
    "    # Get sequence for the target year\n",
    "    target_year_normalized = (year - 2000) / (2023 - 2000)\n",
    "    current_seq = country_data.tail(seq_length)[[\"Country_Encoded\", \"year\", \"avg_temperature\", \"co2_emissions\", \"deforestation_rate\"]].values\n",
    "    \n",
    "    # Iteratively predict for future years\n",
    "    while current_seq[-1, 1] < target_year_normalized:\n",
    "        seq = current_seq.reshape(1, seq_length, 5)\n",
    "        predicted_temp = temp_model.predict(seq, verbose=0)[0][0]\n",
    "        predicted_co2 = co2_model.predict(seq, verbose=0)[0][0]\n",
    "        predicted_deforestation = deforestation_model.predict(seq, verbose=0)[0][0]\n",
    "        \n",
    "        new_year = current_seq[-1, 1] + 1 / (2023 - 2000)\n",
    "        new_row = np.array([current_seq[-1, 0], new_year, predicted_temp, predicted_co2, predicted_deforestation])\n",
    "        current_seq = np.vstack((current_seq[1:], new_row))\n",
    "    \n",
    "    # Final prediction\n",
    "    seq = current_seq.reshape(1, seq_length, 5)\n",
    "    predicted_temp = temp_model.predict(seq, verbose=0)[0][0]\n",
    "    predicted_co2 = co2_model.predict(seq, verbose=0)[0][0]\n",
    "    predicted_deforestation = deforestation_model.predict(seq, verbose=0)[0][0]\n",
    "    \n",
    "    # Inverse transform predictions\n",
    "    dummy_array = np.zeros((1, 5))\n",
    "    dummy_array[0, 2] = predicted_temp\n",
    "    dummy_array[0, 3] = predicted_co2\n",
    "    dummy_array[0, 4] = predicted_deforestation\n",
    "    predicted_values = scaler_x.inverse_transform(dummy_array)[:, 2:]\n",
    "    \n",
    "    return {\n",
    "        \"Predicted Temperature (°C)\": round(predicted_values[0, 0], 2),\n",
    "        \"Predicted CO2 Emissions (MMT)\": round(predicted_values[0, 1], 2),\n",
    "        \"Predicted Deforestation Rate (%)\": round(predicted_values[0, 2], 2),\n",
    "    }\n",
    "\n",
    "# Test Predictions\n",
    "try:\n",
    "    country = input(\"🌍 Enter Country: \")\n",
    "    year = int(input(\"📅 Enter Year: \"))\n",
    "    prediction = predict_climate_lstm(country, year, data)\n",
    "    if prediction:\n",
    "        print(\"📊 Predicted Climate Impact:\")\n",
    "        print(prediction)\n",
    "    \n",
    "        # Test multiple years\n",
    "        print(f\"\\nTesting predictions for {country} across years:\")\n",
    "        for test_year in [2005, 2010, 2015, 2020, 2025]:\n",
    "            prediction = predict_climate_lstm(country, test_year, data)\n",
    "            if prediction:\n",
    "                print(f\"Year {test_year}:\")\n",
    "                print(prediction)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", str(e))\n",
    "except Exception as e:\n",
    "    print(\"Unexpected error:\", str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
